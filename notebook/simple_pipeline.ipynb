{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main steps:\n",
    "\n",
    "1. Look at the big picture.\n",
    "2. Get the data.\n",
    "3. Explore and visualize the data to gain insights.\n",
    "4. Prepare the data for machine learning algorithms.\n",
    "5. Select a model and train it.\n",
    "6. Output as CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_56644/3214603956.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "import numpy as numpy\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import mord as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load the data from the DrivenData competition into a pandas dataframe\n",
    "\n",
    "    Returns:\n",
    "        Pandas dataframes of the training values, training labels, test values,\n",
    "        and submission format\n",
    "    \"\"\"\n",
    "\n",
    "    # The submission format\n",
    "    # submission_format\n",
    "    # this is what our .csv output file should look like\n",
    "    # make sure damage_grade is integer, not float!\n",
    "    url_submission_format = ('https://drivendata-prod.s3.amazonaws.com/data/57/public/submission_format.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYQTZTLQOS%2F20240201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240201T103937Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2546ac2508675ca4e0161409520fab1e3552e9342e03468074572960192fc12c')\n",
    "    submission_format = pd.read_csv(url_submission_format)\n",
    "\n",
    "    # The test values\n",
    "    url_test_values = ('https://drivendata-prod.s3.amazonaws.com/data/57/public/test_values.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYQTZTLQOS%2F20240201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240201T103937Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=5782f88e43df91a5b05951c6c868b1b9699b281042a38066e35aacba349e329c')\n",
    "    test_values = pd.read_csv(url_test_values, index_col='building_id')\n",
    "\n",
    "    # The training labels\n",
    "    url_train_labels = ('https://drivendata-prod.s3.amazonaws.com/data/57/public/train_labels.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYQTZTLQOS%2F20240201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240201T103937Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=36d24a38b88f5c6a4acddcbbc1db9b6518b71e50ec03a74fbe84fc30a62a9acc')\n",
    "    train_labels = pd.read_csv(url_train_labels, index_col='building_id')\n",
    "\n",
    "    # The training features\n",
    "    url_train_values = ('https://drivendata-prod.s3.amazonaws.com/data/57/public/train_values.csv?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIARVBOBDCYQTZTLQOS%2F20240201%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240201T103937Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=be3146653c1a73b442dce121ce46ccef21a67a28347eefc2c62c473eff0a00e8')\n",
    "    train_values = pd.read_csv(url_train_values, index_col='building_id')\n",
    "\n",
    "    return train_values, train_labels, test_values, submission_format\n",
    "\n",
    "train_values, train_labels, test_values, submission_format = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess the data\n",
    "def preprocess_data(train_values, train_labels):\n",
    "    # Select only numerical columns\n",
    "    numerical_train_values = train_values.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    train_values_scaled = scaler.fit_transform(numerical_train_values)\n",
    "\n",
    "    # Ensure labels are integers\n",
    "    train_labels = train_labels.astype(int)\n",
    "\n",
    "    return train_values_scaled, train_labels\n",
    "\n",
    "# Preprocess data\n",
    "X_train, y_train = preprocess_data(train_values, train_labels['damage_grade'])  # Assuming 'damage_grade' is the label column\n",
    "\n",
    "def preprocess_test_data(test_values):\n",
    "    # Select only numerical columns\n",
    "    numerical_test_values = test_values.select_dtypes(include=['number'])\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    test_values_scaled = scaler.fit_transform(numerical_test_values)\n",
    "    \n",
    "    return test_values_scaled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explore and visualise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ordinal_logistic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mtrain_ordinal_logistic\u001b[0;34m(X_train, y_train)\u001b[0m\n\u001b[1;32m     17\u001b[0m X_train_scaled \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Initialize and train the LogisticAT model (which stands for Logistic All Thresholds)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mm\u001b[49m\u001b[38;5;241m.\u001b[39mLogisticAT()\n\u001b[1;32m     21\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[0;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "#Select a model and train it\n",
    "\n",
    "def train_ordinal_logistic(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train an ordinal logistic regression model using the LogisticAT model from mord.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training feature set.\n",
    "    - y_train: Training target variable.\n",
    "\n",
    "    Returns:\n",
    "    - The trained ordinal logistic regression model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Standardize features by removing the mean and scaling to unit variance\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # Initialize and train the LogisticAT model (which stands for Logistic All Thresholds)\n",
    "    model = m.LogisticAT()\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train the model\n",
    "model = train_ordinal_logistic(X_train, y_train)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "\n",
    "\n",
    "def predict(model, test_values, submission_format):\n",
    "    \"\"\"\n",
    "    Make predictions with a trained model on the test dataset and format the output for competition submission.\n",
    "\n",
    "    Parameters:\n",
    "    - model: The trained machine learning model.\n",
    "    - test_values: The raw features of the test dataset (prior to preprocessing).\n",
    "    - submission_format: A DataFrame providing the format required for submission, including an ID column.\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame containing predictions in the required submission format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Preprocess test data using the existing function\n",
    "    test_values_preprocessed = preprocess_test_data(test_values)\n",
    "\n",
    "    # Make predictions on preprocessed test data\n",
    "    predictions = model.predict(test_values_preprocessed)\n",
    "\n",
    "    # Format predictions for submission using the submission_format DataFrame\n",
    "    formatted_predictions = submission_format.copy()\n",
    "    formatted_predictions['damage_grade'] = predictions.astype(int)  # Ensure predictions are integers\n",
    "\n",
    "    return formatted_predictions\n",
    "\n",
    "# Example usage, assuming test_values and submission_format are defined\n",
    "formatted_predictions = predict(model, test_values, submission_format)\n",
    "\n",
    "# To save the predictions to a CSV file compatible with the competition's submission format\n",
    "formatted_predictions.to_csv('submission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output as CSV"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsr-setup",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
