{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../submissions')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from load import load_train_data, load_test_data\n",
    "from evaluate import evaluate_model\n",
    "from utils import save_submission, save_model, load_model\n",
    "from encoding import freq_encode, get_house_volume\n",
    "from datetime import datetime\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, TargetEncoder, FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = load_train_data(local=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for preprocessing and modelling\n",
    "TARGET = 'damage_grade'\n",
    "\n",
    "X = train_data.copy()\n",
    "y = train_data.pop(TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation sets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2,\n",
    "                                                      stratify=y,\n",
    "                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              objective='multi:softprob', predictor=None, ...):\n",
      "F1-score (validation): 0.745\n",
      "F1-score (training): 0.745\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "base_line_pipeline = load_model('../models/model_baseline.pickle')\n",
    "\n",
    "y_train_ = y_train.copy()\n",
    "y_valid_ = y_valid.copy()\n",
    "\n",
    "new_model = XGBClassifier(random_state=42)\n",
    "\n",
    "new_pipeline = base_line_pipeline.set_params(model=new_model)\n",
    "\n",
    "# Evaluate model performance\n",
    "if \"xgboost\" in str(type(new_model)):\n",
    "    y_train_ = y_train_.apply(lambda x: int(x-1))\n",
    "    y_valid_ = y_valid_.apply(lambda x: int(x-1))\n",
    "    \n",
    "score_valid, score_training = evaluate_model(new_pipeline, X_train, X_valid, y_train_, y_valid_)\n",
    "print(f\"{new_model}:\")\n",
    "print(f\"F1-score (validation): {score_valid :.3f}\")\n",
    "print(f\"F1-score (training): {score_training :.3f}\")\n",
    "print(\"________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbasic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
